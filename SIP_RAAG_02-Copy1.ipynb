{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22f2f91-9c9b-420c-9a01-eebb35507fc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chosen model Resjump\n",
      "Generating Initial Buffer...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.nn import GINConv\n",
    "from torch_geometric.utils import degree\n",
    "import random\n",
    "import numpy as np\n",
    "import copy\n",
    "import gc\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import JumpingKnowledge, global_add_pool\n",
    "\n",
    "\n",
    "# The specific imports for Graph Neural Networks\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GINConv\n",
    "\n",
    "# --- 1. RAAG DEFINITION ---\n",
    "# Commutation Graph: Even nodes commute with the next odd node\n",
    "RAAG_ADJ = np.zeros((2001, 2001))\n",
    "for i in range(2000):\n",
    "    if i % 2 == 0:\n",
    "        RAAG_ADJ[i][i+1] = 1\n",
    "        RAAG_ADJ[i+1][i] = 1\n",
    "\n",
    "class RAAGWord:\n",
    "    def __init__(self, letters, adj_matrix=RAAG_ADJ):\n",
    "        self.adj_matrix = adj_matrix\n",
    "        self.letters = self.reduce(letters)\n",
    "\n",
    "    def reduce(self, lts):\n",
    "        # SAFETY CAP: Prevent \"Infinite Growth\" memory explosion\n",
    "        if len(lts) > 60: lts = lts[:60]\n",
    "        \n",
    "        res = []\n",
    "        for l in lts:\n",
    "            if not res:\n",
    "                res.append(l)\n",
    "                continue\n",
    "            idx = len(res) - 1\n",
    "            can_cancel = False\n",
    "            while idx >= 0:\n",
    "                if res[idx] == -l:\n",
    "                    can_cancel = True\n",
    "                    break\n",
    "                if not self.adj_matrix[abs(l)][abs(res[idx])]:\n",
    "                    break\n",
    "                idx -= 1\n",
    "            if can_cancel:\n",
    "                res.pop(idx)\n",
    "            else:\n",
    "                res.append(l)\n",
    "        return res\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        return RAAGWord(self.letters + other.letters, self.adj_matrix)\n",
    "\n",
    "    def inv(self):\n",
    "        return RAAGWord([-l for l in reversed(self.letters)], self.adj_matrix)\n",
    "\n",
    "# --- 2. ALGEBRAIC MOVES & FAN TOPOLOGY ---\n",
    "def apply_nielsen_moves_fixed(subgroup_basis, num_moves=10):\n",
    "    scrambled = list(subgroup_basis)\n",
    "    rank = len(scrambled)\n",
    "    for _ in range(num_moves):\n",
    "        i, j = random.sample(range(rank), 2)\n",
    "        op = random.choice(['mul', 'inv_mul'])\n",
    "        if op == 'mul':\n",
    "            scrambled[i] = (scrambled[i][0] * scrambled[j][0], scrambled[i][1] * scrambled[j][1])\n",
    "        else:\n",
    "            j_inv = (scrambled[j][0].inv(), scrambled[j][1].inv())\n",
    "            scrambled[i] = (scrambled[i][0] * j_inv[0], scrambled[i][1] * j_inv[1])\n",
    "    return scrambled\n",
    "\n",
    "def subgroup_to_graph(subgroup):\n",
    "    x, edge_index = [], []\n",
    "    \n",
    "    # 1. Create Hubs (Nodes 0-4)\n",
    "    for i in range(5):\n",
    "        x.append([float(501 + i)]) \n",
    "    \n",
    "    curr_idx = 5\n",
    "    for i, (w_a, w_b) in enumerate(subgroup):\n",
    "        hub_idx = i\n",
    "        full_word = w_a.letters + w_b.letters\n",
    "        if not full_word: full_word = [0]\n",
    "        for letter in full_word:\n",
    "            x.append([float(letter)])\n",
    "            edge_index.append([curr_idx, hub_idx])\n",
    "            edge_index.append([hub_idx, curr_idx])\n",
    "            curr_idx += 1\n",
    "    \n",
    "    x_tensor = torch.tensor(x, dtype=torch.float)\n",
    "    edge_index_tensor = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    \n",
    "    # --- ADD THESE LINES TO FIX THE ERROR ---\n",
    "    # Calculate degree: how many edges are connected to each node\n",
    "    deg = degree(edge_index_tensor[0], num_nodes=x_tensor.size(0))\n",
    "    \n",
    "    # Create node_type: 0 for Hubs (first 5), 1 for Letters\n",
    "    node_type = torch.ones(x_tensor.size(0), dtype=torch.long)\n",
    "    node_type[:5] = 0 \n",
    "    \n",
    "    return Data(\n",
    "        x=x_tensor, \n",
    "        edge_index=edge_index_tensor, \n",
    "        degree=deg,          # Fixes the AttributeError\n",
    "        node_type=node_type  # Needed for the Hub-pooling logic\n",
    "    )\n",
    "\n",
    "def subgroup_to_graph_old(subgroup):\n",
    "    \"\"\"FAN TOPOLOGY: Connects every letter directly to its hub.\"\"\"\n",
    "    x, edge_index = [], []\n",
    "    for i in range(5): x.append([float(501 + i)]) # 5 Hubs\n",
    "    \n",
    "    curr_idx = 5\n",
    "    for i, (w_a, w_b) in enumerate(subgroup):\n",
    "        hub_idx = i\n",
    "        full_word = w_a.letters + w_b.letters\n",
    "        if not full_word: full_word = [0]\n",
    "        for letter in full_word:\n",
    "            x.append([float(letter)])\n",
    "            edge_index.append([curr_idx, hub_idx])\n",
    "            edge_index.append([hub_idx, curr_idx])\n",
    "            curr_idx += 1\n",
    "            \n",
    "    return Data(x=torch.tensor(x, dtype=torch.float),\n",
    "                edge_index=torch.tensor(edge_index, dtype=torch.long).t().contiguous())\n",
    "\n",
    "\n",
    "# --- 4. KERNEL-SAFE DATA GENERATION ---\n",
    "def triplet_generator(batch_size, nielsen_moves):\n",
    "    \"\"\"LAZY GENERATOR: Never creates more than one batch at a time.\"\"\"\n",
    "    while True:\n",
    "        triplets = []\n",
    "        for _ in range(batch_size):\n",
    "            shift = random.randint(-400, 400)\n",
    "            base_sub = [(RAAGWord([shift + i]), RAAGWord([shift + i + 100])) for i in range(5)]\n",
    "            \n",
    "            anchor = apply_nielsen_moves_fixed(base_sub, num_moves=random.randint(1, 5))\n",
    "            pos = apply_nielsen_moves_fixed(base_sub, num_moves=nielsen_moves)\n",
    "            \n",
    "            # Surgical Negative: Change one generator only\n",
    "            neg = copy.deepcopy(anchor)\n",
    "            idx = random.randint(0, 4)\n",
    "            neg[idx] = (RAAGWord([random.randint(-1000, 1000)]), neg[idx][1])\n",
    "            \n",
    "            triplets.append((subgroup_to_graph(anchor), subgroup_to_graph(pos), subgroup_to_graph(neg)))\n",
    "        \n",
    "        yield (Batch.from_data_list([t[0] for t in triplets]),\n",
    "               Batch.from_data_list([t[1] for t in triplets]),\n",
    "               Batch.from_data_list([t[2] for t in triplets]))\n",
    "\n",
    "def generate_triplets_hardened_v2(num_samples, nielsen_moves, surgical_prob=0.5):\n",
    "    \"\"\"\n",
    "    Generates a large batch of triplets.\n",
    "    surgical_prob: Probability of a 'Surgical' negative (hard) vs 'Alphabet' (easy).\n",
    "    \"\"\"\n",
    "    triplets = []\n",
    "    for _ in range(num_samples):\n",
    "        # 1. Setup Base\n",
    "        shift = random.randint(-600, 600)\n",
    "        # Generators A and B are 100 apart in the alphabet\n",
    "        base_sub = [(RAAGWord([shift + i]), RAAGWord([shift + i + 100])) for i in range(5)]\n",
    "\n",
    "        # 2. Positive Pair (Anchor and Scrambled)\n",
    "        # Anchor gets a light scramble (1-5 moves) so it's not \"perfect\"\n",
    "        anchor_sub = apply_nielsen_moves_fixed(base_sub, num_moves=random.randint(1, 5))\n",
    "        # Positive gets the full scramble\n",
    "        pos_sub = apply_nielsen_moves_fixed(base_sub, num_moves=nielsen_moves)\n",
    "\n",
    "        # 3. Negative Pair\n",
    "        if random.random() < surgical_prob:\n",
    "            # HARD NEGATIVE: Take the anchor and change one generator to a random letter\n",
    "            neg_sub = copy.deepcopy(anchor_sub)\n",
    "            idx = random.randint(0, 4)\n",
    "            # Replace one generator in the pair with a random one\n",
    "            neg_sub[idx] = (RAAGWord([random.randint(-1000, 1000)]), neg_sub[idx][1])\n",
    "        else:\n",
    "            # EASY NEGATIVE: Pick a completely different alphabet range\n",
    "            # Ensure the new shift is far away from the original shift\n",
    "            alt_shift = random.choice([s for s in range(-600, 600) if abs(s - shift) > 200])\n",
    "            neg_base = [(RAAGWord([alt_shift + i]), RAAGWord([alt_shift + i + 100])) for i in range(5)]\n",
    "            neg_sub = apply_nielsen_moves_fixed(neg_base, num_moves=random.randint(1, 5))\n",
    "\n",
    "        triplets.append((\n",
    "            subgroup_to_graph(anchor_sub),\n",
    "            subgroup_to_graph(pos_sub),\n",
    "            subgroup_to_graph(neg_sub)\n",
    "        ))\n",
    "    return triplets\n",
    "\n",
    "def generate_triplets_v4(num_samples, nielsen_moves, hard_prob=0.8):\n",
    "    \"\"\"\n",
    "    V4: Includes Algebraic Dependency Decoys.\n",
    "    Forces the model to distinguish between a full-rank subgroup \n",
    "    and one where a generator is just a product of the others.\n",
    "    \"\"\"\n",
    "    triplets = []\n",
    "    for _ in range(num_samples):\n",
    "        # 1. Setup Anchor\n",
    "        shift = random.randint(-500, 500)\n",
    "        base_sub = [(RAAGWord([shift + i]), RAAGWord([shift + i + 100])) for i in range(5)]\n",
    "        \n",
    "        anchor_sub = apply_nielsen_moves_fixed(base_sub, num_moves=random.randint(1, 5))\n",
    "        pos_sub = apply_nielsen_moves_fixed(base_sub, num_moves=nielsen_moves)\n",
    "\n",
    "        # 2. Select Negative Type\n",
    "        dice = random.random()\n",
    "        \n",
    "        if dice < (hard_prob * 0.8):\n",
    "            # TYPE A: ALGEBRAIC DEPENDENCY (The Hardest)\n",
    "            # Replace Slot 4 with Slot 0 * Slot 1. Alphabet is identical, algebra is collapsed.\n",
    "            neg_sub = copy.deepcopy(anchor_sub)\n",
    "            i, j = random.sample(range(4), 2) # Pick two to combine\n",
    "            idx_to_kill = 4                   # Replace the 5th\n",
    "            \n",
    "            # Create a product: g_new = g_i * g_j\n",
    "            combined = (neg_sub[i][0] * neg_sub[j][0], neg_sub[i][1] * neg_sub[j][1])\n",
    "            neg_sub[idx_to_kill] = combined\n",
    "            \n",
    "            # Scramble to hide the length of the product\n",
    "            neg_sub = apply_nielsen_moves_fixed(neg_sub, num_moves=nielsen_moves)\n",
    "\n",
    "        elif dice < hard_prob:\n",
    "            # TYPE B: SURGICAL SUBSTITUTION\n",
    "            # Replace one generator with a random one from a far-away alphabet\n",
    "            neg_sub = copy.deepcopy(anchor_sub)\n",
    "            idx = random.randint(0, 4)\n",
    "            bad_shift = random.choice([s for s in range(-1000, 1000) if abs(s - shift) > 300])\n",
    "            neg_sub[idx] = (RAAGWord([bad_shift]), RAAGWord([bad_shift + 50]))\n",
    "            neg_sub = apply_nielsen_moves_fixed(neg_sub, num_moves=nielsen_moves)\n",
    "\n",
    "        else:\n",
    "            # TYPE C: EASY ALPHABET SHIFT\n",
    "            alt_shift = random.choice([s for s in range(-600, 600) if abs(s - shift) > 200])\n",
    "            neg_base = [(RAAGWord([alt_shift + i]), RAAGWord([alt_shift + i + 100])) for i in range(5)]\n",
    "            neg_sub = apply_nielsen_moves_fixed(neg_base, num_moves=5)\n",
    "\n",
    "        triplets.append((\n",
    "            subgroup_to_graph(anchor_sub),\n",
    "            subgroup_to_graph(pos_sub),\n",
    "            subgroup_to_graph(neg_sub)\n",
    "        ))\n",
    "    return triplets\n",
    "\n",
    "# --- REFINED MODEL FOR NUMERICAL REASONING ---\n",
    "class UniversalHubGNN(nn.Module):\n",
    "    def __init__(self, hidden=256): # Increased hidden size for 512 batch\n",
    "        super().__init__()\n",
    "        # Linear encoder treats node IDs as coordinates, not just labels\n",
    "        self.node_encoder = nn.Linear(1, hidden) \n",
    "        self.lin_deg = nn.Linear(1, hidden)\n",
    "        self.convs = nn.ModuleList([\n",
    "            GINConv(nn.Sequential(nn.Linear(hidden, hidden), nn.ReLU(), nn.Linear(hidden, hidden)))\n",
    "            for _ in range(4) # Reduced layers to 4 to speed up 512-batch processing\n",
    "        ])\n",
    "        self.lns = nn.ModuleList([nn.LayerNorm(hidden) for _ in range(4)])\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(5 * hidden, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, 64)\n",
    "        )\n",
    "\n",
    "    def forward_one(self, data):\n",
    "        # Normalize node values to help the Linear layer see the 'Alphabet'\n",
    "        x = self.node_encoder(data.x / 1000.0) \n",
    "        \n",
    "        row, _ = data.edge_index\n",
    "        deg = torch.zeros((data.x.size(0), 1), device=data.x.device)\n",
    "        deg.scatter_add_(0, row.unsqueeze(1), torch.ones((row.size(0), 1), device=data.x.device))\n",
    "        x = x + self.lin_deg(deg)\n",
    "\n",
    "        for conv, ln in zip(self.convs, self.lns):\n",
    "            h = conv(x, data.edge_index)\n",
    "            x = ln(F.relu(h) + x) # Removed Dropout to stabilize large batch loss\n",
    "\n",
    "        # Pooling logic...\n",
    "        num_graphs = data.num_graphs if hasattr(data, 'num_graphs') else 1\n",
    "        hub_embeddings = []\n",
    "        if hasattr(data, 'ptr') and data.ptr is not None:\n",
    "            for i in range(num_graphs):\n",
    "                start = data.ptr[i]\n",
    "                hub_embeddings.append(x[start : start + 5].reshape(-1))\n",
    "        else:\n",
    "            hub_embeddings.append(x[:5].reshape(-1))\n",
    "\n",
    "        return F.normalize(self.fc(torch.stack(hub_embeddings)), p=2, dim=1)\n",
    "\n",
    "\n",
    "class WideHubGNN(nn.Module):\n",
    "    def __init__(self, hidden_channels=512, out_emb=128, num_layers=5):\n",
    "        super(WideHubGNN, self).__init__()\n",
    "        \n",
    "        # 1. Wide Input Encoding\n",
    "        self.node_encoder = nn.Linear(1, hidden_channels)\n",
    "        self.deg_encoder = nn.Linear(1, hidden_channels)\n",
    "        \n",
    "        # 2. GIN Layers with Residual Setup\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.batch_norms = nn.ModuleList()\n",
    "        \n",
    "        for _ in range(num_layers):\n",
    "            mlp = nn.Sequential(\n",
    "                nn.Linear(hidden_channels, hidden_channels * 2),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_channels * 2, hidden_channels),\n",
    "                nn.BatchNorm1d(hidden_channels)\n",
    "            )\n",
    "            self.convs.append(GINConv(mlp))\n",
    "            self.batch_norms.append(nn.BatchNorm1d(hidden_channels))\n",
    "\n",
    "        # 3. Jumping Knowledge: Remembers \"Clean\" features from early layers\n",
    "        self.jk = JumpingKnowledge(mode='cat', channels=hidden_channels, num_layers=num_layers)\n",
    "        # Assuming: hidden_channels=512, num_layers=5\n",
    "        jk_size = hidden_channels * num_layers # 512 * 5 = 2560\n",
    "        total_hub_input = jk_size * 5          # 2560 * 5 = 12800\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(total_hub_input, 1024),  # Changed from 2560 to 12800\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, out_emb)           # out_emb is your final 64 or 128\n",
    "        )\n",
    "\n",
    "    def forward_one(self, data):\n",
    "        # data.x: [TotalNodes, 1]\n",
    "        # data.edge_index: [2, TotalEdges]\n",
    "        # data.batch: [TotalNodes] \n",
    "        # data.degree: [TotalNodes]\n",
    "        # data.node_type: [TotalNodes] (0 for hubs, 1 for letters)\n",
    "    \n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        # 1. Input Encoding: Normalize node values and add structural degree signal\n",
    "        # Shape: [TotalNodes, hidden_channels]\n",
    "        deg = data.degree.view(-1, 1).float() / 100.0 \n",
    "        x = self.node_encoder(x / 1000.0) + self.deg_encoder(deg)\n",
    "        \n",
    "        layer_outputs = []\n",
    "        \n",
    "        # 2. Message Passing with Residual Connections\n",
    "        for conv, bn in zip(self.convs, self.batch_norms):\n",
    "            identity = x # Save for skip connection\n",
    "            h = conv(x, edge_index)\n",
    "            x = bn(F.relu(h + identity)) # Residual Step\n",
    "            layer_outputs.append(x) # Save state for Jumping Knowledge\n",
    "            \n",
    "        # 3. Jumping Knowledge: Concatenate all layer outputs\n",
    "        # If hidden=512 and num_layers=5, x_jk shape: [TotalNodes, 2560]\n",
    "        x_jk = self.jk(layer_outputs)\n",
    "        \n",
    "        # 4. Hub Extraction (The \"Slot-Aware\" part)\n",
    "        # node_type == 0 marks our 5 Generators (Hubs)\n",
    "        hub_mask = (data.node_type == 0)\n",
    "        h_hubs = x_jk[hub_mask] \n",
    "        # Shape: [BatchSize * 5, 2560]\n",
    "        \n",
    "        # 5. Flattening for the Decision Head\n",
    "        # We combine the 5 hubs into one long feature vector for the MLP\n",
    "        # Shape: [BatchSize, 12800]\n",
    "        h_hubs = h_hubs.view(-1, 5 * x_jk.size(-1))\n",
    "        \n",
    "        # 6. Final Projection & Normalization\n",
    "        # Project 12800 -> 1024 -> out_emb (e.g., 128)\n",
    "        out = self.fc(h_hubs)\n",
    "        \n",
    "        # Return L2-normalized embedding for Cosine Similarity\n",
    "        return F.normalize(out, p=2, dim=1)\n",
    "        \n",
    "    def forward(self, anchor, positive, negative):\n",
    "        # Triplet Forward Pass\n",
    "        return self.forward_one(anchor), self.forward_one(positive), self.forward_one(negative)\n",
    "\n",
    "def generate_triplets_v4(num_samples, nielsen_moves, hard_prob=0.8):\n",
    "    triplets = []\n",
    "    for _ in range(num_samples):\n",
    "        shift = random.randint(-500, 500)\n",
    "        base_sub = [(RAAGWord([shift + i]), RAAGWord([shift + i + 100])) for i in range(5)]\n",
    "        anchor_sub = apply_nielsen_moves_fixed(base_sub, num_moves=random.randint(1, 5))\n",
    "        pos_sub = apply_nielsen_moves_fixed(base_sub, num_moves=nielsen_moves)\n",
    "\n",
    "        dice = random.random()\n",
    "        if dice < (hard_prob * 0.8):\n",
    "            neg_type = 0 # ALGEBRAIC\n",
    "            neg_sub = copy.deepcopy(anchor_sub)\n",
    "            i, j = random.sample(range(4), 2)\n",
    "            neg_sub[4] = (neg_sub[i][0] * neg_sub[j][0], neg_sub[i][1] * neg_sub[j][1])\n",
    "            neg_sub = apply_nielsen_moves_fixed(neg_sub, num_moves=nielsen_moves)\n",
    "        elif dice < hard_prob:\n",
    "            neg_type = 1 # SURGICAL\n",
    "            neg_sub = copy.deepcopy(anchor_sub)\n",
    "            idx = random.randint(0, 4)\n",
    "            bad_shift = random.choice([s for s in range(-1000, 1000) if abs(s - shift) > 300])\n",
    "            neg_sub[idx] = (RAAGWord([bad_shift]), RAAGWord([bad_shift + 50]))\n",
    "            neg_sub = apply_nielsen_moves_fixed(neg_sub, num_moves=nielsen_moves)\n",
    "        else:\n",
    "            neg_type = 2 # ALPHABET\n",
    "            alt_shift = random.choice([s for s in range(-600, 600) if abs(s - shift) > 200])\n",
    "            neg_base = [(RAAGWord([alt_shift + i]), RAAGWord([alt_shift + i + 100])) for i in range(5)]\n",
    "            neg_sub = apply_nielsen_moves_fixed(neg_base, num_moves=5)\n",
    "\n",
    "        # Create graphs\n",
    "        a_graph, p_graph, n_graph = subgroup_to_graph(anchor_sub), subgroup_to_graph(pos_sub), subgroup_to_graph(neg_sub)\n",
    "        \n",
    "        # Attach the label to the anchor so we can retrieve it in the batch\n",
    "        a_graph.neg_type = torch.tensor([neg_type])\n",
    "        \n",
    "        triplets.append((a_graph, p_graph, n_graph))\n",
    "    return triplets\n",
    "\n",
    "class ResJumperGNN(nn.Module):\n",
    "    def __init__(self, hidden_channels=256, out_emb=128, num_layers=4):\n",
    "        super(ResJumperGNN, self).__init__()\n",
    "        \n",
    "        self.node_encoder = nn.Linear(1, hidden_channels)\n",
    "        self.deg_encoder = nn.Linear(1, hidden_channels)\n",
    "        \n",
    "        self.convs = nn.ModuleList()\n",
    "        self.batch_norms = nn.ModuleList()\n",
    "        \n",
    "        for _ in range(num_layers):\n",
    "            # GIN with a lighter MLP internal structure\n",
    "            mlp = nn.Sequential(\n",
    "                nn.Linear(hidden_channels, hidden_channels),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_channels, hidden_channels),\n",
    "                nn.BatchNorm1d(hidden_channels)\n",
    "            )\n",
    "            self.convs.append(GINConv(mlp))\n",
    "            self.batch_norms.append(nn.BatchNorm1d(hidden_channels))\n",
    "\n",
    "        # Jumping Knowledge (JK) is great for RAAGs because it \n",
    "        # keeps the 'local' alphabet info available at the final layer.\n",
    "        self.jk = JumpingKnowledge(mode='cat', channels=hidden_channels, num_layers=num_layers)\n",
    "        \n",
    "        # Calculation: 256 channels * 4 layers = 1024 features per node\n",
    "        jk_size = hidden_channels * num_layers \n",
    "        \n",
    "        # Instead of 12800 -> 1024, we do a more efficient 5120 -> 512\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(jk_size * 5, 512), \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1), # Added a touch of dropout for regularization\n",
    "            nn.Linear(512, out_emb)\n",
    "        )\n",
    "\n",
    "    def forward_one(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        # 1. Input Encoding\n",
    "        deg = data.degree.view(-1, 1).float() / 100.0 \n",
    "        x = self.node_encoder(x / 1000.0) + self.deg_encoder(deg)\n",
    "        \n",
    "        layer_outputs = []\n",
    "        \n",
    "        # 2. Residual Message Passing\n",
    "        for conv, bn in zip(self.convs, self.batch_norms):\n",
    "            h = conv(x, edge_index)\n",
    "            x = bn(F.relu(h + x)) # Skip connection\n",
    "            layer_outputs.append(x)\n",
    "            \n",
    "        # 3. Jumping Knowledge\n",
    "        x_jk = self.jk(layer_outputs)\n",
    "        \n",
    "        # 4. Slot-Aware Hub Extraction\n",
    "        # We still look specifically at our 5 Hub nodes\n",
    "        hub_mask = (data.node_type == 0)\n",
    "        h_hubs = x_jk[hub_mask] \n",
    "        \n",
    "        # Reshape to [Batch, 5 * JK_Size]\n",
    "        # This keeps the 'order' of generators, which is vital for Algebraic checks\n",
    "        h_hubs = h_hubs.view(-1, 5 * x_jk.size(-1))\n",
    "        \n",
    "        # 5. Output\n",
    "        out = self.fc(h_hubs)\n",
    "        return F.normalize(out, p=2, dim=1)\n",
    "\n",
    "class TwinFlowGNN(nn.Module):\n",
    "    def __init__(self, hidden=192, bottleneck=64, out_emb=64):\n",
    "        super().__init__()\n",
    "        # Use a more sensitive encoder for the node values\n",
    "        self.node_enc = nn.Sequential(\n",
    "            nn.Linear(1, hidden),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden, hidden)\n",
    "        )\n",
    "        \n",
    "        # 3-Layer GIN: Deep enough for Nielsen moves, shallow enough to stay stable\n",
    "        self.convs = nn.ModuleList([\n",
    "            GINConv(nn.Sequential(nn.Linear(hidden, hidden), nn.ReLU(), nn.Linear(hidden, hidden)))\n",
    "            for _ in range(3)\n",
    "        ])\n",
    "        \n",
    "        # The Bottleneck: Forces the model to discard alphabet noise\n",
    "        self.bottleneck = nn.Linear(hidden * 5, bottleneck)\n",
    "        \n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(bottleneck, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, out_emb)\n",
    "        )\n",
    "\n",
    "    def forward_one(self, data):\n",
    "        # Normalize input rigorously: [min_id, max_id] -> [0, 1]\n",
    "        x = self.node_enc(data.x / 1000.0)\n",
    "        \n",
    "        for conv in self.convs:\n",
    "            x = F.relu(conv(x, data.edge_index) + x) # Residual help\n",
    "            \n",
    "        # Extract the 5 Hubs\n",
    "        hub_mask = (data.node_type == 0)\n",
    "        h_hubs = x[hub_mask].view(-1, 5 * x.size(-1))\n",
    "        \n",
    "        # Force through bottleneck\n",
    "        b = F.relu(self.bottleneck(h_hubs))\n",
    "        \n",
    "        return F.normalize(self.head(b), p=2, dim=1)\n",
    "\n",
    "@torch.no_grad()\n",
    "def refresh_buffer_with_mining(model, current_buffer, device, target_size=65536, margin = 1.0):\n",
    "    model.eval()\n",
    "    all_losses = []\n",
    "    \n",
    "    # 1. Score the current buffer\n",
    "    # Use a small loader to get through the buffer quickly\n",
    "    temp_loader = DataLoader(current_buffer, batch_size=128, shuffle=False)\n",
    "    \n",
    "    for a, p, n in temp_loader:\n",
    "        a, p, n = a.to(device), p.to(device), n.to(device)\n",
    "        ea, ep, en = model.forward_one(a), model.forward_one(p), model.forward_one(n)\n",
    "        \n",
    "        # Calculate individual triplet losses (reduction='none' is key here)\n",
    "        # It gives us one loss value per triplet instead of an average\n",
    "        d_pos = torch.norm(ea - ep, p=2, dim=1)\n",
    "        d_neg = torch.norm(ea - en, p=2, dim=1)\n",
    "        # Margin = 1.0 (recommended to increase this)\n",
    "        losses = torch.clamp(d_pos - d_neg + margin, min=0.0)\n",
    "        all_losses.extend(losses.cpu().numpy())\n",
    "\n",
    "    # 2. Identify the Hardest Triplets\n",
    "    # Sort indices by loss (descending)\n",
    "    indices = np.argsort(all_losses)[::-1]\n",
    "    \n",
    "    # Keep the top 50% (the ones the model is failing on)\n",
    "    num_to_keep = int(target_size * 0.01)\n",
    "    hard_indices = indices[:num_to_keep]\n",
    "    new_buffer = [current_buffer[i] for i in hard_indices]\n",
    "    \n",
    "    # 3. Fill the rest with fresh \"unseen\" challenges\n",
    "    print(f\"Keeping {num_to_keep} hard samples. Generating fresh challenges...\")\n",
    "    fresh_samples = generate_triplets_v4(target_size - num_to_keep, nielsen_moves=15)\n",
    "    new_buffer.extend(fresh_samples)\n",
    "    \n",
    "    return new_buffer\n",
    "\n",
    "# --- SPEED-OPTIMIZED TRAINING ---\n",
    "\n",
    "cases = ['Resjump', 'Wide', 'Twin', 'Universal']\n",
    "device = torch.device('cuda')\n",
    "\n",
    "for case in cases:\n",
    "\n",
    "    if case == cases[0]:\n",
    "        model = TwinFlowGNN(hidden = 256, out_emb = 128).to(device)\n",
    "    elif case == cases[1]:\n",
    "        model = UniversalHubGNN(hidden = 256, out_emb = 128).to(device)\n",
    "    elif case == cases[2]:\n",
    "        model = TwinFlowGNN().to(device)\n",
    "    elif case == cases[3]:\n",
    "        model = UniversalHubGNN().to(device)\n",
    "\n",
    "    print(f'\\nChosen model {case}')\n",
    "        \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005) # Higher LR for large batch\n",
    "    criterion = nn.TripletMarginLoss(margin=0.5)\n",
    "    \n",
    "    # Generate a large buffer ONCE to keep GPU saturated\n",
    "    print(\"Generating Initial Buffer...\")\n",
    "    NUM_SAMPLES = 32768\n",
    "    train_buffer = generate_triplets_v4(NUM_SAMPLES, nielsen_moves=15)\n",
    "    \n",
    "    \n",
    "    # Training parameters\n",
    "    MARGIN = 1.0 # Increased margin\n",
    "    criterion = nn.TripletMarginLoss(margin=MARGIN)\n",
    "    \n",
    "    for epoch in range(1500):\n",
    "        # --- HARD NEGATIVE MINING STEP ---\n",
    "        if epoch > 0 and epoch % 5 == 0:\n",
    "            print(f\"--- Epoch {epoch}: Swapping 90% of samples\")\n",
    "            train_buffer = refresh_buffer_with_mining(model, train_buffer, device, target_size=NUM_SAMPLES, margin = 0.5)  \n",
    "            #train_buffer = generate_triplets_v4(NUM_SAMPLES, nielsen_moves=15)\n",
    "            \n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        loader = DataLoader(train_buffer, batch_size=128, shuffle=True)\n",
    "        \n",
    "        for a, p, n in loader:\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            a, p, n = a.to(device), p.to(device), n.to(device)\n",
    "            \n",
    "            ea, ep, en = model.forward_one(a), model.forward_one(p), model.forward_one(n)\n",
    "            \n",
    "            loss = criterion(ea, ep, en)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient Clipping: Prevents the model from 'exploding' when it hits \n",
    "            # a very difficult algebraic negative\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        print(f\"Epoch {epoch} | Average Loss: {total_loss/len(loader):.6f}\")\n",
    "        \n",
    "    torch.save(model.state_dict(), f'model_{case}_{NUM_SAMPLES}_nightly_01.pth')\n",
    "\n",
    "    \n",
    "\"\"\"\n",
    "for epoch in range(200):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    # We rebuild the loader so it sees the refreshed buffer\n",
    "    loader = DataLoader(train_buffer, batch_size=64, shuffle=True)\n",
    "    \n",
    "    for a, p, n in loader:\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        \n",
    "        # 1. Move to device\n",
    "        a, p, n = a.to(device), p.to(device), n.to(device)\n",
    "        \n",
    "        # 2. Forward pass\n",
    "        ea = model.forward_one(a)\n",
    "        ep = model.forward_one(p)\n",
    "        en = model.forward_one(n)\n",
    "        \n",
    "        # 3. Compute loss\n",
    "        loss = criterion(ea, ep, en)\n",
    "        loss.backward()\n",
    "        \n",
    "        # 4. Step\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # --- MEMORY GUARD ---\n",
    "        # Explicitly delete the batch tensors to free GPU memory immediately\n",
    "        del a, p, n, ea, ep, en, loss\n",
    "\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    print(f\"Epoch {epoch} | Loss: {avg_loss}\")    \n",
    "    # --- BUFFER REFRESH LOGIC ---\n",
    "    # Refreshing 20% of the buffer every 5 epochs\n",
    "    if epoch % 5 == 0:\n",
    "        print(\"Refreshing 50% of buffer...\")\n",
    "        num_to_refresh = int(len(train_buffer) * 0.5)\n",
    "        \n",
    "        # Generate new samples on CPU\n",
    "        new_samples = generate_triplets_v4(num_to_refresh, nielsen_moves=15)\n",
    "        \n",
    "        # Randomly replace entries in the existing list\n",
    "        indices = random.sample(range(len(train_buffer)), num_to_refresh)\n",
    "        for idx, sample in zip(indices, new_samples):\n",
    "            # Overwriting the index helps prevent memory fragmentation\n",
    "            train_buffer[idx] = sample\n",
    "            \n",
    "        # Clear the sample list and force garbage collection\n",
    "        del new_samples\n",
    "        gc.collect() \n",
    "        torch.cuda.empty_cache() # Essential for WideHubGNN (512+ channels) \"\"\"\n",
    "\n",
    "torch.save(model.state_dict(), f'model_wideHub_{NUM_SAMPLES}_5.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90f52b75-e5df-4ea5-9a77-6a3126e914ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'model_wideHub_{NUM_SAMPLES}_4.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "437e66a9-df74-4bad-b841-4bfd10d5300d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UniversalHubGNN(\n",
       "  (node_encoder): Linear(in_features=1, out_features=256, bias=True)\n",
       "  (lin_deg): Linear(in_features=1, out_features=256, bias=True)\n",
       "  (convs): ModuleList(\n",
       "    (0-3): 4 x GINConv(nn=Sequential(\n",
       "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    ))\n",
       "  )\n",
       "  (lns): ModuleList(\n",
       "    (0-3): 4 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=1280, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Create the architecture instance (must match the saved one exactly)\n",
    "# Ensure the hidden/bottleneck sizes match what you used during training!\n",
    "model = TwinFlowGNN(hidden=192, bottleneck=64, out_emb=64)\n",
    "model = ResJumperGNN()\n",
    "model = WideHubGNN()\n",
    "model = UniversalHubGNN()\n",
    "\n",
    "# 2. Load the weights\n",
    "# map_location ensures it works even if you trained on GPU but are loading on CPU\n",
    "state_dict = torch.load('model_Twin_32768_nightly_01.pth', map_location=torch.device('cpu'))\n",
    "state_dict = torch.load('model_Resjump_32768_nightly_01.pth', map_location=torch.device('cpu'))\n",
    "state_dict = torch.load('model_Wide_32768_nightly_01.pth', map_location=torch.device('cpu'))\n",
    "state_dict = torch.load('model_Universal_32768_nightly_01.pth', map_location=torch.device('cpu'))\n",
    "\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "# 3. Move to GPU (if available) and set to evaluation mode\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6458f5b3-17d1-4c44-8052-8f6de0d578e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÜ Final Accuracy: 2.0%\n"
     ]
    }
   ],
   "source": [
    "def test_vault_crack(model, device, num_decoys=10, nielsen_moves=15):\n",
    "    model.eval()\n",
    "    \n",
    "    # 1. Create the 'Secret' (The Anchor)\n",
    "    secret_shift = random.randint(-400, 400)\n",
    "    secret_basis = [(RAAGWord([secret_shift + i]), RAAGWord([secret_shift + i + 100])) for i in range(5)]\n",
    "    anchor_graph = subgroup_to_graph(secret_basis).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Get the 'fingerprint' of our secret\n",
    "        anchor_emb = model.forward_one(anchor_graph)\n",
    "\n",
    "    # 2. Setup the Vault\n",
    "    vault_graphs = []\n",
    "    correct_idx = random.randint(0, num_decoys)\n",
    "    \n",
    "    for i in range(num_decoys + 1):\n",
    "        if i == correct_idx:\n",
    "            # The True Secret (heavily scrambled)\n",
    "            sub = apply_nielsen_moves_fixed(secret_basis, num_moves=nielsen_moves)\n",
    "        else:\n",
    "            # Decoy: Different alphabet, different algebra\n",
    "            r_shift = random.choice([s for s in range(-600, 600) if abs(s - secret_shift) > 150])\n",
    "            sub = [(RAAGWord([r_shift + j]), RAAGWord([r_shift + j + 100])) for j in range(5)]\n",
    "            sub = apply_nielsen_moves_fixed(sub, num_moves=random.randint(1, 10))\n",
    "            \n",
    "        vault_graphs.append(subgroup_to_graph(sub))\n",
    "\n",
    "    # Add another 25 decoys with one generator replaced by a random other generator\n",
    "    for _ in range(32):\n",
    "        # Start with a copy of the secret\n",
    "        surgical = copy.deepcopy(secret_basis)\n",
    "        \n",
    "        # Pick one random slot (0-4) to corrupt\n",
    "        idx_to_corrupt = random.randint(0, 4)\n",
    "        \n",
    "        # Create a random imposter generator from a far-away alphabet\n",
    "        bad_shift = random.choice([s for s in range(-1000, 1000) if abs(s - secret_shift) > 300])\n",
    "        imposter = (RAAGWord([bad_shift]), RAAGWord([bad_shift + 50]))\n",
    "        \n",
    "        # Replace the generator\n",
    "        surgical[idx_to_corrupt] = imposter\n",
    "        \n",
    "        # Scramble the result so the \"clean\" imposter doesn't stand out \n",
    "        # to a simple pattern matcher\n",
    "        sub = apply_nielsen_moves_fixed(surgical, num_moves=5)\n",
    "        \n",
    "        vault_graphs.append(subgroup_to_graph(sub))\n",
    "        num_decoys += 1\n",
    "\n",
    "    # TYPE 6: Algebraic Dependency (The Hardest Decoy)\n",
    "    for _ in range(32):\n",
    "        # 1. Start with the secret basis\n",
    "        hard_decoy = copy.deepcopy(secret_basis)\n",
    "        \n",
    "        # 2. Pick a target slot to \"destroy\" (e.g., Slot 4)\n",
    "        idx_to_replace = 4\n",
    "        \n",
    "        # 3. Pick two other slots to combine (e.g., Slot 0 and Slot 1)\n",
    "        # We replace g_4 with (g_0 * g_1)\n",
    "        i, j = random.sample([x for x in range(5) if x != idx_to_replace], 2)\n",
    "        \n",
    "        combined_gen = (\n",
    "            hard_decoy[i][0] * hard_decoy[j][0], \n",
    "            hard_decoy[i][1] * hard_decoy[j][1]\n",
    "        )\n",
    "        \n",
    "        hard_decoy[idx_to_replace] = combined_gen\n",
    "        \n",
    "        # 4. Scramble it! \n",
    "        # Without this, the model might see that one hub has a very long word.\n",
    "        # Nielsen moves redistribute the word length across all hubs.\n",
    "        sub = apply_nielsen_moves_fixed(hard_decoy, num_moves=15)\n",
    "        \n",
    "        vault_graphs.append(subgroup_to_graph(sub))\n",
    "        num_decoys += 1\n",
    "\n",
    "    # 3. The Crack Operation (Batch Processing for Speed)\n",
    "    loader = DataLoader(vault_graphs, batch_size=32)\n",
    "    vault_embs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            emb = model.forward_one(batch.to(device))\n",
    "            vault_embs.append(emb)\n",
    "    \n",
    "    vault_embs = torch.cat(vault_embs, dim=0)\n",
    "\n",
    "    # 4. Calculate Similarities\n",
    "    # We use Cosine Similarity to see how close the 'fingerprint' is to each vault item\n",
    "    similarities = F.cosine_similarity(anchor_emb, vault_embs).cpu().numpy()\n",
    "    \n",
    "    # 5. Results\n",
    "    predicted_idx = np.argmax(similarities)\n",
    "    top_5_indices = np.argsort(similarities)[-5:][::-1]\n",
    "    \n",
    "    #print(f\"Correct Index: {correct_idx} | Predicted Index: {predicted_idx} with similarity {similarities[predicted_idx]}\")\n",
    "    \n",
    "    if predicted_idx == correct_idx:\n",
    "        #print(\"‚úÖ SUCCESS: The GNN cracked the vault!\")\n",
    "        rank = 1\n",
    "    else:\n",
    "        rank = list(np.argsort(similarities)[::-1]).index(correct_idx) + 1\n",
    "        #print(f\"‚ùå FAILURE: The secret was ranked #{rank} out of {num_decoys+1}\")\n",
    "        \n",
    "    return predicted_idx == correct_idx, rank\n",
    "\n",
    "# Run 10 trials to get an accuracy percentage\n",
    "success_count = 0\n",
    "trials = 100\n",
    "\n",
    "ranks = []\n",
    "for t in range(trials):\n",
    "    success, rank = test_vault_crack(model, device, num_decoys=32, nielsen_moves=15)\n",
    "    ranks.append(rank)\n",
    "    if success:\n",
    "        success_count += 1\n",
    "\n",
    "print(f\"\\nüèÜ Final Accuracy: {success_count/trials * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd080381-e9f1-4e9a-a243-6aececab1123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(ranks, bins = 128)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "976a55a5-160d-4a0d-b8e5-fe85c2acdaf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "üìà CRYPTANALYSIS REPORT\n",
      "==============================\n",
      "Top-1 Accuracy:  6.00%\n",
      "Top-5 Accuracy:  28.00%\n",
      "Mean Rank:       19.14 / 115\n",
      "------------------------------\n",
      "SIMILARITY PROFILES (The Fingerprint Strength):\n",
      " > ALPHABET  : -0.2043\n",
      " > SURGICAL  : -0.5009\n",
      " > ALGEBRAIC : 0.6266\n",
      " > SECRET    : 0.7280\n"
     ]
    }
   ],
   "source": [
    "def test_vault_scientific(model, device, num_basic=50, nielsen_moves=15):\n",
    "    model.eval()\n",
    "    \n",
    "    # 1. Setup the Secret (Anchor)\n",
    "    secret_shift = random.randint(-400, 400)\n",
    "    secret_basis = [(RAAGWord([secret_shift + i]), RAAGWord([secret_shift + i + 100])) for i in range(5)]\n",
    "    anchor_graph = subgroup_to_graph(secret_basis).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        anchor_emb = model.forward_one(anchor_graph)\n",
    "\n",
    "    vault_graphs = []\n",
    "    labels = [] # To keep track of what is what\n",
    "    \n",
    "    # --- CATEGORY 1: THE TRUE POSITIVE ---\n",
    "    correct_idx = 0 # We'll keep it at 0 and shuffle later\n",
    "    true_secret_sub = apply_nielsen_moves_fixed(secret_basis, num_moves=nielsen_moves)\n",
    "    vault_graphs.append(subgroup_to_graph(true_secret_sub))\n",
    "    labels.append(\"SECRET\")\n",
    "\n",
    "    # --- CATEGORY 2: BASIC ALPHABET DECOYS ---\n",
    "    for _ in range(num_basic):\n",
    "        r_shift = random.choice([s for s in range(-600, 600) if abs(s - secret_shift) > 150])\n",
    "        sub = [(RAAGWord([r_shift + j]), RAAGWord([r_shift + j + 100])) for j in range(5)]\n",
    "        sub = apply_nielsen_moves_fixed(sub, num_moves=random.randint(1, 10))\n",
    "        vault_graphs.append(subgroup_to_graph(sub))\n",
    "        labels.append(\"ALPHABET\")\n",
    "\n",
    "    # --- CATEGORY 3: SURGICAL DECOYS (1-GEN REPLACED) ---\n",
    "    for _ in range(32):\n",
    "        surgical = copy.deepcopy(secret_basis)\n",
    "        idx_to_corrupt = random.randint(0, 4)\n",
    "        bad_shift = random.choice([s for s in range(-1000, 1000) if abs(s - secret_shift) > 300])\n",
    "        surgical[idx_to_corrupt] = (RAAGWord([bad_shift]), RAAGWord([bad_shift + 50]))\n",
    "        sub = apply_nielsen_moves_fixed(surgical, num_moves=5)\n",
    "        vault_graphs.append(subgroup_to_graph(sub))\n",
    "        labels.append(\"SURGICAL\")\n",
    "\n",
    "    # --- CATEGORY 4: ALGEBRAIC DEPENDENCY (THE COLLAPSE) ---\n",
    "    for _ in range(32):\n",
    "        hard_decoy = copy.deepcopy(secret_basis)\n",
    "        i, j = random.sample(range(4), 2)\n",
    "        hard_decoy[4] = (hard_decoy[i][0] * hard_decoy[j][0], hard_decoy[i][1] * hard_decoy[j][1])\n",
    "        sub = apply_nielsen_moves_fixed(hard_decoy, num_moves=15)\n",
    "        vault_graphs.append(subgroup_to_graph(sub))\n",
    "        labels.append(\"ALGEBRAIC\")\n",
    "\n",
    "    # 3. Batch Process Embeddings\n",
    "    loader = DataLoader(vault_graphs, batch_size=32)\n",
    "    vault_embs = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            vault_embs.append(model.forward_one(batch.to(device)))\n",
    "    vault_embs = torch.cat(vault_embs, dim=0)\n",
    "\n",
    "    # 4. Analysis\n",
    "    similarities = F.cosine_similarity(anchor_emb, vault_embs).cpu().numpy()\n",
    "    \n",
    "    # Map results by category\n",
    "    results = {\"SECRET\": [], \"ALPHABET\": [], \"SURGICAL\": [], \"ALGEBRAIC\": []}\n",
    "    for sim, label in zip(similarities, labels):\n",
    "        results[label].append(sim)\n",
    "\n",
    "    predicted_idx = np.argmax(similarities)\n",
    "    sorted_indices = np.argsort(similarities)[::-1]\n",
    "    rank = list(sorted_indices).index(0) + 1 # Rank of the actual secret (index 0)\n",
    "    \n",
    "    return rank, results\n",
    "\n",
    "# --- RUN MULTIPLE TRIALS ---\n",
    "trials = 50\n",
    "rank_history = []\n",
    "category_stats = {\"ALPHABET\": [], \"SURGICAL\": [], \"ALGEBRAIC\": [], \"SECRET\": []}\n",
    "\n",
    "for t in range(trials):\n",
    "    rank, trial_results = test_vault_scientific(model, device)\n",
    "    rank_history.append(rank)\n",
    "    for k in category_stats:\n",
    "        category_stats[k].append(np.mean(trial_results[k]))\n",
    "\n",
    "# --- FINAL REPORT ---\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(\"üìà CRYPTANALYSIS REPORT\")\n",
    "print(\"=\"*30)\n",
    "print(f\"Top-1 Accuracy:  { (np.array(rank_history) == 1).mean() * 100:.2f}%\")\n",
    "print(f\"Top-5 Accuracy:  { (np.array(rank_history) <= 5).mean() * 100:.2f}%\")\n",
    "print(f\"Mean Rank:       { np.mean(rank_history):.2f} / 115\")\n",
    "print(\"-\" * 30)\n",
    "print(\"SIMILARITY PROFILES (The Fingerprint Strength):\")\n",
    "for cat, scores in category_stats.items():\n",
    "    print(f\" > {cat:10}: {np.mean(scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8573731-8cc1-4855-af6a-e4ae041a5541",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
